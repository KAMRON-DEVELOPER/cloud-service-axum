# 1. Create the dedicated namespace
apiVersion: v1
kind: Namespace
metadata:
  name: infra-kafka
---
# 2. One-time-setup ConfigMap for the Cluster ID
#    You must create this *once*.
#    Run these commands:
#
#    export CLUSTER_ID=$(kubectl run -i --rm --tty uuid-gen --image=busybox --restart=Never --command -- cat /proc/sys/kernel/random/uuid)
#    kubectl create configmap kafka-cluster-id -n infra-kafka --from-literal=CLUSTER_ID=$CLUSTER_ID
#
apiVersion: v1
kind: ConfigMap
metadata:
  name: kafka-cluster-id
  namespace: infra-kafka
data:
  CLUSTER_ID: "<your-generated-uuid-goes-here>" # e.g. "mk-4-gLpTjGUPN1R-nN3ow"
---
# 3. The "Headless" Service (REQUIRED for StatefulSet)
apiVersion: v1
kind: Service
metadata:
  name: kafka-service
  namespace: infra-kafka
spec:
  clusterIP: None # Headless
  publishNotReadyAddresses: true # Important for pod startup
  selector:
    app: kafka
  ports:
    - name: kafka
      protocol: TCP
      port: 9092
      targetPort: 9092
    - name: controller
      protocol: TCP
      port: 9093
      targetPort: 9093
---
# 4. The StatefulSet for a 3-node KRaft cluster
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
  namespace: infra-kafka
spec:
  serviceName: "kafka-service"
  replicas: 3 # We want 3 nodes for high availability
  podManagementPolicy: Parallel
  selector:
    matchLabels:
      app: kafka

  # 5. This template will create 'kafka-data-kafka-0', 'kafka-data-kafka-1', etc.
  volumeClaimTemplates:
    - metadata:
        name: kafka-data
      spec:
        accessModes: ["ReadWriteOnce"]
        resources:
          requests:
            storage: 10Gi

  template:
    metadata:
      labels:
        app: kafka
    spec:
      volumes:
        # Mount the ConfigMap with the cluster ID
        - name: kafka-config
          configMap:
            name: kafka-cluster-id
      containers:
        - name: kafka
          image: apache/kafka:3.6.1 # Use a specific version, not :latest
          ports:
            - containerPort: 9092
              name: kafka
            - containerPort: 9093
              name: controller
          volumeMounts:
            - name: kafka-data
              mountPath: /var/lib/kafka/data
            - name: kafka-config
              mountPath: /config
          env:
            - name: KAFKA_PROCESS_ROLES
              value: "broker,controller"
            - name: KAFKA_CONTROLLER_LISTENER_NAMES
              value: "CONTROLLER"
            - name: KAFKA_LISTENERS
              value: "PLAINTEXT://:9092,CONTROLLER://:9093"

            # This is the dynamic list of ALL controller nodes
            - name: KAFKA_CONTROLLER_QUORUM_VOTERS
              value: "0@kafka-0.kafka-service.infra-kafka.svc.cluster.local:9093,1@kafka-1.kafka-service.infra-kafka.svc.cluster.local:9093,2@kafka-2.kafka-service.infra-kafka.svc.cluster.local:9093"

            - name: KAFKA_LOG_DIRS
              value: "/var/lib/kafka/data"

            # 6. Now we can have a proper replication factor
            - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
              value: "3"
            - name: KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
              value: "3"
            - name: KAFKA_TRANSACTION_STATE_LOG_MIN_ISR
              value: "2" # Minimum in-sync replicas

          # 7. This script runs on start to configure each pod uniquely
          command: ["/bin/bash", "-c"]
          args:
            - |
              set -e

              # Get the pod's index (0, 1, or 2) from its hostname
              export KAFKA_NODE_ID=${HOSTNAME##*-}

              # Set advertised listener to this pod's unique DNS name
              export KAFKA_ADVERTISED_LISTENERS="PLAINTEXT://${HOSTNAME}.kafka-service.infra-kafka.svc.cluster.local:9092"

              # Get the shared Cluster ID
              export KAFKA_CLUSTER_ID=$(cat /config/CLUSTER_ID)

              CONFIG_FILE="/opt/kafka/config/kraft/server.properties"

              # Format storage *only if* it's not already formatted
              if [ ! -f /var/lib/kafka/data/meta.properties ]; then
                echo "Formatting storage for node $KAFKA_NODE_ID..."
                /opt/kafka/bin/kafka-storage.sh format -t $KAFKA_CLUSTER_ID -c $CONFIG_FILE
              else
                echo "Storage already formatted for node $KAFKA_NODE_ID"
              fi

              # Start Kafka
              echo "Starting Kafka server for node $KAFKA_NODE_ID..."
              /opt/kafka/bin/kafka-server-start.sh $CONFIG_FILE
